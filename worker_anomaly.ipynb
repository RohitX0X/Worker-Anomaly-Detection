{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, List\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# simulate a data with 10 columns , timestamp, worker id {1,10} , Travel time, Assignment duration , day of the week, month ,location , My plan is to train a ML model on this\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "from typing import Optional, List\n",
    "# simulate a data with 10 columns , timestamp, worker id {1,10} , Travel time, Assignment duration , day of the week, month ,location , My plan is to train a ML model on this\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class Generator():\n",
    "  def __init__(self, n_operators: int = 5, location_list: Optional[List[str]] = None, ):\n",
    "    self.n_operators = n_operators\n",
    "    self.location_list = location_list\n",
    "    if self.location_list is None:\n",
    "      self.location_list = [f\"location_{i}\" for i in \"abcdef\"]\n",
    "    pass\n",
    "\n",
    "  def generate_data(self, num_rows: int=100000, months: int = 1):\n",
    "      start_date = datetime(2023, 1, 1)\n",
    "      # end_date = datetime(2023, 1+ months, 31)\n",
    "\n",
    "      data = []\n",
    "      for _ in range(num_rows):\n",
    "          hour_of_day = random.randint(8, 17)\n",
    "          timestamp = start_date + timedelta(days=random.randint(0, 6),\n",
    "                                            hours=hour_of_day,\n",
    "                                            minutes=random.randint(0, 59))\n",
    "          \n",
    "          worker_id = random.randint(1, self.n_operators)\n",
    "          \n",
    "          travel_time = random.randint(15, 120)  # in seconds\n",
    "\n",
    "          assignment_duration = travel_time + random.randint(300, 600)  # in seconds\n",
    "\n",
    "          # Special Cases\n",
    "          if(worker_id in [1]):\n",
    "            travel_time = 90 + random.randint(-10,10)\n",
    "            assignment_duration = 500 + random.randint(-40,40)\n",
    "          elif(hour_of_day in [15,16,17]):\n",
    "            travel_time = 100 + random.randint(-10,10)\n",
    "            assignment_duration = 450 + random.randint(-40,40)\n",
    "          else:\n",
    "            pass\n",
    "          \n",
    "          day_of_week = timestamp.weekday()\n",
    "          month = timestamp.month\n",
    "          location = random.choice(self.location_list)\n",
    "\n",
    "          data.append([timestamp, worker_id, travel_time, assignment_duration,\n",
    "                      day_of_week, hour_of_day, month, location])\n",
    "      \n",
    "      # randomly append 20 anomaly data points and shuffle\n",
    "      for _ in range(3):\n",
    "        hour_of_day = random.randint(8, 17)\n",
    "        travel_time = random.randint(15, 120)\n",
    "        assignment_duration = travel_time + random.randint(300, 600)\n",
    "\n",
    "        anomaly_choice = random.randint(1, 3)\n",
    "        if anomaly_choice == 1:\n",
    "          hour_of_day = random.randint(19, 21)\n",
    "        elif anomaly_choice >= 2:\n",
    "          travel_time = random.randint(15000, 17000)\n",
    "        else:\n",
    "          assignment_duration = random.randint(50, 60)\n",
    "\n",
    "        timestamp = start_date + timedelta(days=random.randint(0, 6),\n",
    "                                            hours=hour_of_day,\n",
    "                                            minutes=random.randint(0, 59))\n",
    "        worker_id = random.randint(1, self.n_operators)\n",
    "        day_of_week = timestamp.weekday()\n",
    "        month = timestamp.month\n",
    "        location = random.choice(self.location_list)\n",
    "        data.append([timestamp, worker_id, travel_time, assignment_duration, day_of_week, hour_of_day, month, location])  # Anomaly: travel_time=900, assignment_duration=1000\n",
    "      \n",
    "      random.shuffle(data)\n",
    "\n",
    "      df = pd.DataFrame(data,\n",
    "                        columns=[\"timestamp\", \"worker_id\", \"travel_time\",\n",
    "                                \"assignment_duration\", \"day_of_week\", \"hour_of_day\" , \"month\",\n",
    "                                \"location\"])\n",
    "      return df\n",
    "\n",
    "gnr = Generator(4)\n",
    "\n",
    "df = gnr.generate_data()\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Prepare the data for the model\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the selected columns\n",
    "scaler.fit(df[['travel_time', 'assignment_duration']])\n",
    "\n",
    "# Transform the selected columns using the scaler\n",
    "df[['travel_time_scaled', 'assignment_duration_scaled']] = scaler.transform(df[['travel_time', 'assignment_duration']])\n",
    "\n",
    "# Drop the original columns if desired\n",
    "# df = df.drop(columns=['travel_time', 'assignment_duration'])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "display(df.head())\n",
    "# df = pd.get_dummies(df, columns=['location'])\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# categorical_features = ['hour', 'day_of_week', 'worker_id'] \n",
    "\n",
    "# # Create a OneHotEncoder instance\n",
    "# encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')  # sparse=False for dense output\n",
    "# # encoder = LabelEncoder()  # sparse=False for dense output\n",
    "\n",
    "# # Fit the encoder to the categorical features\n",
    "# encoder.fit(df[categorical_features])\n",
    "\n",
    "# # Transform the categorical features into one-hot encoded features\n",
    "# encoded_features = encoder.transform(df[categorical_features]).astype(int)\n",
    "\n",
    "# # Create column names for the encoded features\n",
    "# encoded_feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# # Create a DataFrame for the encoded features\n",
    "# encoded_df = pd.DataFrame(encoded_features, columns=encoded_feature_names, index=df.index)\n",
    "\n",
    "# # Concatenate the encoded features with the original DataFrame\n",
    "# df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "# # Drop the original categorical features\n",
    "# df = df.drop(columns=categorical_features)\n",
    "# df = df.drop(columns = ['timestamp', 'hour_of_day'])\n",
    "# X = df[:]\n",
    "\n",
    "# Display the preprocessed DataFrame\n",
    "\n",
    "### Encode locations\n",
    "location_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the 'location' column\n",
    "location_encoder.fit(df['location'])\n",
    "\n",
    "# Transform the 'location' column using the encoder\n",
    "df['location_encoded'] = location_encoder.transform(df['location'])\n",
    "\n",
    "# Drop the original 'location' column\n",
    "df = df.drop(columns=['location'])\n",
    "\n",
    "\n",
    "\n",
    "features = ['worker_id', 'travel_time_scaled', 'assignment_duration_scaled', 'day_of_week', 'month', 'hour'] + [col for col in df.columns if 'location' in col]\n",
    "X = df[features]\n",
    "display(X.head())\n",
    "\n",
    "\n",
    "\n",
    "# print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Isolation Forest model\n",
    "print(X.columns)\n",
    "model = IsolationForest(contamination='auto') # Adjust contamination as needed\n",
    "model.fit(X)\n",
    "\n",
    "# Get anomaly predictions\n",
    "df['anomaly_score'] = model.decision_function(X)\n",
    "df['anomaly'] = model.predict(X)\n",
    "\n",
    "# Display the results\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a threshold for anomaly score\n",
    "threshold = -0.005  # Adjust this value as needed\n",
    "\n",
    "# Filter data points with anomaly scores below the threshold\n",
    "high_anomalies = df[df['anomaly_score'] < threshold]\n",
    "\n",
    "# Display the high anomalies\n",
    "# display(high_anomalies)\n",
    "\n",
    "#sort by anomalies\n",
    "df_sorted = df.sort_values(by=['anomaly_score'])\n",
    "top_10_anomalies = df_sorted.head(20)\n",
    "bottom_10_anomalies = df_sorted.tail(20)\n",
    "# display(df.tail(20))\n",
    "display(top_10_anomalies)\n",
    "\n",
    "display(bottom_10_anomalies)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
